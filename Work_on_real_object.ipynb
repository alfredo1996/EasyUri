{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "three-madagascar",
   "metadata": {},
   "source": [
    "Welcome on this second notebook, i will show you how i accomplished on extracting the features from a real photo. Also i will apply the color correction on the photo, showing you the possibilities and the limitations of this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "parallel-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from pyzbar.pyzbar import decode\n",
    "import colour\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "#Reference colors taken from Macbeth Colour Checker\n",
    "#We need them for the color correction\n",
    "real_colors = [\n",
    "[52.0, 52.0, 52.0],\n",
    "[85.0, 85.0, 85.0],\n",
    "[121.0, 122.0, 122.0],\n",
    "[160.0, 160.0, 160.0],\n",
    "[200.0, 200.0, 200.0],\n",
    "[242.0, 243.0, 243.0],\n",
    "[161.0, 133.0, 8.0],\n",
    "[149.0, 86.0, 187.0],\n",
    "[31.0, 199.0, 231.0],\n",
    "[60.0, 54.0, 175.0],\n",
    "[73.0, 148.0, 70.0],\n",
    "[150.0, 61.0, 56.0],\n",
    "[46.0, 163.0, 224.0],\n",
    "[64.0, 188.0, 157.0],\n",
    "[108.0, 60.0, 94.0],\n",
    "[99.0, 90.0, 193.0],\n",
    "[166.0, 91.0, 80.0],\n",
    "[44.0, 126.0, 214.0],\n",
    "[179.0, 189.0, 103.0],\n",
    "[177.0, 128.0, 133.0],\n",
    "[67.0, 108.0, 87.0],\n",
    "[157.0, 122.0, 98.0],\n",
    "[130.0, 150.0, 194.0],\n",
    "[68.0, 82.0, 115.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "built-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the absolute path to read the prototype\n",
    "path = \"C:/Users/User Pc/Desktop/Progetto OpenCV/All notebooks/real_photo.jpeg\"\n",
    "img = cv2.imread(path)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Method to incapsulate the imshow, just for prettify the code\n",
    "\"\"\"\n",
    "def imshow(img, name = \"img\"):\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "This method is the preprocessing pipeline. I needed to \n",
    "change it from the classic method because the \n",
    "first implementation wasn't enough efficient on \n",
    "extracting the corners without introducing noise inside\n",
    "its output.\n",
    "\"\"\"\n",
    "def bilateralFilteringPreprocessing(img):\n",
    "    \n",
    "    #Get only one channel\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Blur the image using gaussian blur\n",
    "    imgBlur = cv2.GaussianBlur(gray,(7,7),2)\n",
    "    \n",
    "    # Smoothing without removing edges.\n",
    "    gray_filtered = cv2.bilateralFilter(gray, 9, 60, 120)\n",
    "  \n",
    "    # Applying the canny filter\n",
    "    edges_filtered = cv2.Canny(gray_filtered, 30, 50) \n",
    "\n",
    "    return edges_filtered\n",
    "\n",
    "imshow(img)\n",
    "imshow(bilateralFilteringPreprocessing(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-cyprus",
   "metadata": {},
   "source": [
    "Extract the QrCode coords and remove it from the photo, defining two different images:\n",
    "\n",
    "1) References, for color correction\n",
    "\n",
    "2) Chemical pads, for the result of the analysis\n",
    "\n",
    "I've tried different photos, but i will show only this one for now, because sometimes the shadows inside the photo can be problematic for the qrCode decoding. I think i can try to change the pipeline not using the qrCode, but i need to redesign the operations we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "planned-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the image in input, extract the QrCode and return \n",
    "the upper part of the image and the lower part\n",
    "\"\"\"\n",
    "def qrCodeExtraction(img):\n",
    "    \n",
    "    #Method of pyzbar that decodes the image\n",
    "    qrCode = decode(img)[0]\n",
    "    \n",
    "    #Contains different basic object, we need the polygon\n",
    "    #because it contains the four points of the bounding box\n",
    "    polygon = qrCode.polygon\n",
    "    \n",
    "    #Find min and max of the y_coords of the qrCode\n",
    "    qrCode_min_y = min(value.y for value in polygon)\n",
    "    qrCode_max_y = max(value.y for value in polygon)\n",
    "    \n",
    "    #Divide the img in two different ones\n",
    "    references = img[:qrCode_min_y-10].copy()\n",
    "    chemical_pads = img[qrCode_max_y:].copy()\n",
    "    \n",
    "    return qrCode_min_y, qrCode_max_y,references, chemical_pads\n",
    "\n",
    "qrCode_min_y, qrCode_max_y, references, chemical_pads = qrCodeExtraction(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-reynolds",
   "metadata": {},
   "source": [
    "Method useful to study the different contours that OpenCV finds inside the image. Is important to notice that bigger images bring with them bigger noises, so is necessary the definition of some practices useful to remove the noises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method that return all the lines in the tester and also the min and max points \n",
    "from them, so that we can crop the image\n",
    "\"\"\"\n",
    "def getContourWithDefinedNumber(img, numberDesired):\n",
    "    \n",
    "  imgContour = img.copy()\n",
    "  imgCanny = bilateralFilteringPreprocessing(img)\n",
    "  #Store couple [[x_Start,y_Start], [X_End,y_End]] for each contour that we found\n",
    "  #with the desired number of boundary points\n",
    "  output = []\n",
    "\n",
    "  #Extract all the contours from the img\n",
    "  contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_LIST,\n",
    "                                        cv2.CHAIN_APPROX_NONE)\n",
    "  #For each contour found\n",
    "  for cnt in contours:\n",
    "        \n",
    "    #Calculate the approximative Polygon to extract only the lines from the photo\n",
    "    peri = cv2.arcLength(cnt,True)\n",
    "     \n",
    "    #Find the approximative Polygon based on the perimeter and the contour\n",
    "    #approx is a list of points that define the polygon\n",
    "    approx = cv2.approxPolyDP(cnt,0.02 * peri,True)\n",
    "    \n",
    "    #Number of corners of the polygon\n",
    "    objCor = len(approx)\n",
    "    \n",
    "    #Return only the contours that have only the desired value\n",
    "    if (objCor == numberDesired):\n",
    "      \n",
    "      #Draw the desired contour\n",
    "      cv2.drawContours(imgContour,cnt,-1,(255,0,0),1)\n",
    "      \n",
    "      #Define the boundingRect so that, in the case of a line o a square, we have\n",
    "      #The left coordinate, the width and the height\n",
    "      x,y,w,h = cv2.boundingRect(approx)\n",
    "      \n",
    "      #Just for us to visualize the output\n",
    "      cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        \n",
    "      output.append(approx)\n",
    "  #Show the output\n",
    "  imshow(imgContour,str(numberDesired))\n",
    "\n",
    "#Extract the lines from the tester using Canny Algorithm and cv2.drawContours\n",
    "getContourWithDefinedNumber(references,4)\n",
    "getContourWithDefinedNumber(chemical_pads,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Object that packs different methods useful for the color extraction from \n",
    "each bounding box\n",
    "\"\"\"\n",
    "class boxObject():\n",
    "    \n",
    "    #Init method\n",
    "    def __init__(self,x,y,w,h):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.area = w*h\n",
    "    \n",
    "    #Given an image and a radius(predefine at 0.3), the method return the RGB of the area defined by the radius.\n",
    "    def colorInside(self,img, radius = 0.1):\n",
    "        \n",
    "        #Extract the bounding Rect from the photo\n",
    "        imageInside = img[self.y:self.y+self.h,self.x:self.x+self.w].copy()\n",
    "        \n",
    "        #Define the radius based on the w and h of the box\n",
    "        radiusX = round(radius * self.w) \n",
    "        radiusY = round(radius * self.h)\n",
    "        \n",
    "        #Find the center from radiusX and radiusY\n",
    "        center = imageInside[radiusX : 2*radiusX, radiusY : 2*radiusY]\n",
    "        \n",
    "        #Return the BGR of the area\n",
    "        return [round(np.mean(center[:,:,0])),round(np.mean(center[:,:,1])),round(np.mean(center[:,:,2]))]\n",
    "    \n",
    "    def print(self):\n",
    "        print(self.x,self.y,self.h,self.w)\n",
    "    \n",
    "    #Check if other is a duplicate of self\n",
    "    def is_duplicate_of(self, other):\n",
    "        x_dist = abs(self.x - other.x)\n",
    "        y_dist = abs(self.y - other.y)\n",
    "        area_div = self.area/other.area\n",
    "        return (x_dist < 10 and \n",
    "                y_dist < 10 and \n",
    "                area_div > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an image and the number of vertex desired, returns a list\n",
    "that contains the (x,y,w,h) of each elements that has pol edges\n",
    "Used to extract the coordinates of each square\n",
    "\"\"\"\n",
    "def getPolygonCoords(img,pol = 2):\n",
    "  imgContour = img.copy()\n",
    "  #Preprocessing the image\n",
    "  imgCanny = bilateralFilteringPreprocessing(img)\n",
    "    \n",
    "  #Find the contours so that we can choose the ones desired\n",
    "  contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_LIST,\n",
    "                                        cv2.CHAIN_APPROX_NONE)\n",
    "  #Output array\n",
    "  boxes = []\n",
    "    \n",
    "  #For each contours\n",
    "  for cnt in contours:\n",
    "    \n",
    "    #Find the perimeter of the contour\n",
    "    peri = cv2.arcLength(cnt,True)\n",
    "    \n",
    "    #Find the approximative Polygon based on the perimeter and the contour\n",
    "    #approx is a list of points that define the polygon\n",
    "    approx = cv2.approxPolyDP(cnt,0.02 * peri,True)\n",
    "    \n",
    "    #If has the desired number of corners\n",
    "    if (len(approx) == pol):\n",
    "      \n",
    "      #Draw for each contour it's shape\n",
    "      cv2.drawContours(imgContour,cnt,-1,(0,255,0),1)\n",
    "    \n",
    "      #Find the bounding rect of the approximative polygon\n",
    "      x,y,w,h = cv2.boundingRect(approx)\n",
    "        \n",
    "      #Append it to the output array\n",
    "      boxes.append(boxObject(x,y,w,h))\n",
    "  \n",
    "  #Just to show the different boxes extracted\n",
    "  imshow(imgContour)\n",
    "  return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-biodiversity",
   "metadata": {},
   "source": [
    "We can use the different lines inside the tester to cut it in more smaller parts, useful to extract the references and the chemical pads.\n",
    "As you can see running this cell, there is a problem with the background: it is too bright, so is difficult to find the colors inside the references that don't have enough contrast with the background.\n",
    "Two solutions:\n",
    "\n",
    "1) Change background color, but i think is terrible to have a black/dark gray tester.\n",
    "\n",
    "2) Give a contour to each reference color, need to try it, but i think it willgenerate more duplicate for each box, but  created a function that removes the duplicates, so i just need to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suburban-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an image in input, returns the (min,max) of the y_coords of the lines inside the photo.\n",
    "Useful to isolate the references\\chemical_pads\n",
    "\"\"\"\n",
    "def getLinesCoords(img):\n",
    "    l = getPolygonCoords(img,2)\n",
    "    #Choose only the horizontal lines inside the img\n",
    "    lines = [value for value in l if(value.h/value.w <0.1)]\n",
    "    #Compact way to iterate,using the generators functions\n",
    "    y_max = max(value.y for value in lines)\n",
    "    y_min = min(value.y for value in lines)\n",
    "    return y_min,y_max\n",
    "\n",
    "#Find the two lines that define the reference space\n",
    "#Inside the tester\n",
    "y_min_references,y_max_references = getLinesCoords(references)\n",
    "references_isolated = references[y_min_references:y_max_references,:] \n",
    "\n",
    "#Extract the squares and remove the noise\n",
    "references_coords = getPolygonCoords(references_isolated,4)\n",
    "references_squares = [value for value in references_coords if(value.area >10)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-drive",
   "metadata": {},
   "source": [
    "Same problem on the references, need to change the color on the real starting hexadecimal of each chemical pad to see if the proble persists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "annoying-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The exact same thing that i've done for the references, but \n",
    "#for the chemical pads\n",
    "y_min_chemical_pads,y_max_chemical_pads = getLinesCoords(chemical_pads)\n",
    "chemical_pads_isolated = chemical_pads[y_min_chemical_pads:,:] \n",
    "\n",
    "chemical_coords = getPolygonCoords(chemical_pads_isolated,4)\n",
    "chemical_squares = [value for value in chemical_coords if(value.area >10)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-explanation",
   "metadata": {},
   "source": [
    "We need to remove the duplicated contours that openCv finds inside the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intensive-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of boxObjects in input, return a list without all the duplicates\n",
    "\"\"\"\n",
    "def remove_box_duplicates(squares):\n",
    "    set_sq = list()\n",
    "    set_sq.append(squares[0])\n",
    "    #Iterate on each different square and verify that is not a duplicate\n",
    "    for i in range(1,len(squares)):\n",
    "        box = squares[i]\n",
    "        duplicated = False\n",
    "        #Iterate on the set to verify the uniqueness of box\n",
    "        for sq in set_sq:\n",
    "            duplicated = duplicated or box.is_duplicate_of(sq)\n",
    "            if duplicated:\n",
    "                break;\n",
    "        if not duplicated:\n",
    "             set_sq.append(box)\n",
    "    return set_sq\n",
    "\n",
    "set_references_sq = remove_box_duplicates(references_squares)\n",
    "set_chemical_sq = remove_box_duplicates(chemical_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-calgary",
   "metadata": {},
   "source": [
    "Visualization of the different boxes extracted, with a number that indicates their order, from downer left to upper right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "logical-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showIndexedSquares(img, set_sq):\n",
    "    imgContour = img.copy()\n",
    "    i = 0\n",
    "    for value in set_sq:\n",
    "        x = value.x\n",
    "        y = value.y\n",
    "        h = value.h\n",
    "        w = value.w\n",
    "        #Just for us to visualize the output\n",
    "        cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        cv2.putText(\n",
    "         imgContour, #numpy array on which text is written\n",
    "         str(i), #text\n",
    "         (x,y), #position at which writing has to start\n",
    "         cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "         1, #font size\n",
    "         (0,255,0), #font color\n",
    "         3) #font stroke\n",
    "        i = i+1\n",
    "    imshow(imgContour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mighty-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 22\n",
      "511 58\n"
     ]
    }
   ],
   "source": [
    "showIndexedSquares(references_isolated, set_references_sq)\n",
    "showIndexedSquares(chemical_pads_isolated, set_chemical_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-actress",
   "metadata": {},
   "source": [
    "Number taken from the photo + extracted by hand from the photo(just to try, because we need to change the background color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accompanied-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_extracted = list()\n",
    "for value in set_references_sq:\n",
    "    colors_extracted.append(value.colorInside(references_isolated))\n",
    "colors_extracted.insert(5,[169,169,167])\n",
    "colors_extracted.insert(8,[188,158,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-upper",
   "metadata": {},
   "source": [
    "Color correction, as you can see the image changes drastically, but the reference colors don't change too much, need to test more this process or to check if exists better way to correct the colors of the photo. You can also notice that the shadow in the photo introduce a very big noise, so i think could be useful study a way to use the smartphone flashlight in a useful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worse-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_img = morph = img.copy()\n",
    "\n",
    "for im in cali_img:\n",
    "    im[:] = colour.colour_correction(im[:], colors_extracted, real_colors,'Finlayson 2015')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "imshow(cali_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-annual",
   "metadata": {},
   "source": [
    "Trying to use PLS Regression, similar results to the Finlayson Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "pls = PLSRegression(n_components = 3, scale = True, copy = True, tol = 1e-6)\n",
    "                    \n",
    "pls.fit(colors_extracted,real_colors)\n",
    "pls.score(colors_extracted,real_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_img = morph = img.copy()\n",
    "\n",
    "for im in cali_img:\n",
    "    im[:] = pls.predict(im[:])\n",
    "\n",
    "imshow(cali_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-trainer",
   "metadata": {},
   "source": [
    "Extract a second time the colors and the boxes from the photo, using the same points we found earlier on the original img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_references = cali_img[:qrCode_min_y-10].copy()\n",
    "new_chemical_pads = cali_img[qrCode_max_y:].copy()\n",
    "\n",
    "new_references_isolated = new_references[y_min_references:y_max_references,:] \n",
    "new_chemical_pads_isolated = new_chemical_pads[y_min_chemical_pads:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(new_references_isolated)\n",
    "imshow(new_chemical_pads_isolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-invalid",
   "metadata": {},
   "source": [
    "To see how the colors changed, i printed the old and new colors from the two images, the real one and the corrected one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "threaded-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old\n",
      "[17, 88, 111]\n",
      "New\n",
      "[42, 120, 121]\n",
      "**********\n",
      "Old\n",
      "[88, 76, 82]\n",
      "New\n",
      "[143, 126, 136]\n",
      "**********\n",
      "Old\n",
      "[20, 38, 123]\n",
      "New\n",
      "[112, 70, 141]\n",
      "**********\n",
      "Old\n",
      "[108, 105, 103]\n",
      "New\n",
      "[149, 157, 168]\n",
      "**********\n",
      "Old\n",
      "[28, 19, 115]\n",
      "New\n",
      "[142, 52, 139]\n",
      "**********\n",
      "Old\n",
      "[99, 102, 54]\n",
      "New\n",
      "[114, 157, 110]\n",
      "**********\n",
      "Old\n",
      "[60, 77, 105]\n",
      "New\n",
      "[114, 119, 142]\n",
      "**********\n",
      "Old\n",
      "[34, 34, 43]\n",
      "New\n",
      "[93, 76, 64]\n",
      "**********\n",
      "Old\n",
      "[72, 61, 110]\n",
      "New\n",
      "[154, 105, 158]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for value in set_chemical_sq:\n",
    "    \n",
    "    print(\"Old\")\n",
    "    print(value.colorInside(chemical_pads_isolated))\n",
    "    \n",
    "    print(\"New\")\n",
    "    print(value.colorInside(new_chemical_pads_isolated))\n",
    "\n",
    "    print(\"**********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-integer",
   "metadata": {},
   "source": [
    "Some datas about the color correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exciting-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color with index 0\n",
      "Old\n",
      "[36, 55, 64]\n",
      "New\n",
      "[83, 95, 86]\n",
      "Desired\n",
      "[52.0, 52.0, 52.0]\n",
      "Distance from the desired ones\n",
      "[ 31.  43.  34.]\n",
      "**********\n",
      "Color with index 1\n",
      "Old\n",
      "[32, 44, 53]\n",
      "New\n",
      "[84, 84, 72]\n",
      "Desired\n",
      "[85.0, 85.0, 85.0]\n",
      "Distance from the desired ones\n",
      "[ -1.  -1. -13.]\n",
      "**********\n",
      "Color with index 2\n",
      "Old\n",
      "[45, 46, 54]\n",
      "New\n",
      "[102, 89, 82]\n",
      "Desired\n",
      "[121.0, 122.0, 122.0]\n",
      "Distance from the desired ones\n",
      "[-19. -33. -40.]\n",
      "**********\n",
      "Color with index 3\n",
      "Old\n",
      "[68, 68, 69]\n",
      "New\n",
      "[116, 115, 109]\n",
      "Desired\n",
      "[160.0, 160.0, 160.0]\n",
      "Distance from the desired ones\n",
      "[-44. -45. -51.]\n",
      "**********\n",
      "Color with index 4\n",
      "Old\n",
      "[131, 143, 145]\n",
      "New\n",
      "[161, 197, 224]\n",
      "Desired\n",
      "[200.0, 200.0, 200.0]\n",
      "Distance from the desired ones\n",
      "[-39.  -3.  24.]\n",
      "**********\n",
      "Color with index 5\n",
      "Old\n",
      "[169, 169, 167]\n",
      "New\n",
      "[\"not found because openCV can't identify a border\"]\n",
      "Desired\n",
      "[242.0, 243.0, 243.0]\n",
      "Distance from the desired ones\n",
      "There is no number\n",
      "**********\n",
      "Color with index 6\n",
      "Old\n",
      "[80, 66, 34]\n",
      "New\n",
      "[117, 119, 80]\n",
      "Desired\n",
      "[161.0, 133.0, 8.0]\n",
      "Distance from the desired ones\n",
      "[-44. -14.  72.]\n",
      "**********\n",
      "Color with index 7\n",
      "Old\n",
      "[58, 35, 116]\n",
      "New\n",
      "[166, 75, 157]\n",
      "Desired\n",
      "[149.0, 86.0, 187.0]\n",
      "Distance from the desired ones\n",
      "[ 17. -11. -30.]\n",
      "**********\n",
      "Color with index 8\n",
      "Old\n",
      "[188, 158, 32]\n",
      "New\n",
      "[\"not found because openCV can't identify a border\"]\n",
      "Desired\n",
      "[31.0, 199.0, 231.0]\n",
      "Distance from the desired ones\n",
      "There is no number\n",
      "**********\n",
      "Color with index 9\n",
      "Old\n",
      "[32, 52, 125]\n",
      "New\n",
      "[114, 86, 149]\n",
      "Desired\n",
      "[60.0, 54.0, 175.0]\n",
      "Distance from the desired ones\n",
      "[ 54.  32. -26.]\n",
      "**********\n",
      "Color with index 10\n",
      "Old\n",
      "[42, 83, 60]\n",
      "New\n",
      "[56, 126, 82]\n",
      "Desired\n",
      "[73.0, 148.0, 70.0]\n",
      "Distance from the desired ones\n",
      "[-17. -22.  12.]\n",
      "**********\n",
      "Color with index 11\n",
      "Old\n",
      "[54, 24, 45]\n",
      "New\n",
      "[136, 70, 80]\n",
      "Desired\n",
      "[150.0, 61.0, 56.0]\n",
      "Distance from the desired ones\n",
      "[-14.   9.  24.]\n",
      "**********\n",
      "Color with index 12\n",
      "Old\n",
      "[48, 144, 198]\n",
      "New\n",
      "[68, 176, 212]\n",
      "Desired\n",
      "[46.0, 163.0, 224.0]\n",
      "Distance from the desired ones\n",
      "[ 22.  13. -12.]\n",
      "**********\n",
      "Color with index 13\n",
      "Old\n",
      "[44, 143, 133]\n",
      "New\n",
      "[28, 180, 156]\n",
      "Desired\n",
      "[64.0, 188.0, 157.0]\n",
      "Distance from the desired ones\n",
      "[-36.  -8.  -1.]\n",
      "**********\n",
      "Color with index 14\n",
      "Old\n",
      "[38, 32, 59]\n",
      "New\n",
      "[110, 73, 85]\n",
      "Desired\n",
      "[108.0, 60.0, 94.0]\n",
      "Distance from the desired ones\n",
      "[  2.  13.  -9.]\n",
      "**********\n",
      "Color with index 15\n",
      "Old\n",
      "[41, 51, 134]\n",
      "New\n",
      "[133, 86, 164]\n",
      "Desired\n",
      "[99.0, 90.0, 193.0]\n",
      "Distance from the desired ones\n",
      "[ 34.  -4. -29.]\n",
      "**********\n",
      "Color with index 16\n",
      "Old\n",
      "[79, 53, 62]\n",
      "New\n",
      "[147, 103, 112]\n",
      "Desired\n",
      "[166.0, 91.0, 80.0]\n",
      "Distance from the desired ones\n",
      "[-19.  12.  32.]\n",
      "**********\n",
      "Color with index 17\n",
      "Old\n",
      "[26, 97, 171]\n",
      "New\n",
      "[78, 127, 190]\n",
      "Desired\n",
      "[44.0, 126.0, 214.0]\n",
      "Distance from the desired ones\n",
      "[ 34.   1. -24.]\n",
      "**********\n",
      "Color with index 18\n",
      "Old\n",
      "[113, 120, 83]\n",
      "New\n",
      "[128, 176, 148]\n",
      "Desired\n",
      "[179.0, 189.0, 103.0]\n",
      "Distance from the desired ones\n",
      "[-51. -13.  45.]\n",
      "**********\n",
      "Color with index 19\n",
      "Old\n",
      "[96, 73, 87]\n",
      "New\n",
      "[162, 124, 147]\n",
      "Desired\n",
      "[177.0, 128.0, 133.0]\n",
      "Distance from the desired ones\n",
      "[-15.  -4.  14.]\n",
      "**********\n",
      "Color with index 20\n",
      "Old\n",
      "[37, 71, 70]\n",
      "New\n",
      "[68, 111, 91]\n",
      "Desired\n",
      "[67.0, 108.0, 87.0]\n",
      "Distance from the desired ones\n",
      "[ 1.  3.  4.]\n",
      "**********\n",
      "Color with index 21\n",
      "Old\n",
      "[84, 71, 69]\n",
      "New\n",
      "[136, 122, 120]\n",
      "Desired\n",
      "[157.0, 122.0, 98.0]\n",
      "Distance from the desired ones\n",
      "[-21.   0.  22.]\n",
      "**********\n",
      "Color with index 22\n",
      "Old\n",
      "[83, 109, 150]\n",
      "New\n",
      "[134, 152, 202]\n",
      "Desired\n",
      "[130.0, 150.0, 194.0]\n",
      "Distance from the desired ones\n",
      "[ 4.  2.  8.]\n",
      "**********\n",
      "Color with index 23\n",
      "Old\n",
      "[27, 46, 81]\n",
      "New\n",
      "[89, 84, 100]\n",
      "Desired\n",
      "[68.0, 82.0, 115.0]\n",
      "Distance from the desired ones\n",
      "[ 21.   2. -15.]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "new_colors_extracted = list()\n",
    "for value in set_references_sq:\n",
    "    new_colors_extracted.append(value.colorInside(new_references_isolated))\n",
    "new_colors_extracted.insert(5,[\"not found because openCV can't identify a border\"])\n",
    "new_colors_extracted.insert(8,[\"not found because openCV can't identify a border\"])\n",
    "\n",
    "for i in range(len(real_colors)):\n",
    "        print(\"Color with index \" + str(i))\n",
    "        print(\"Old\")\n",
    "        print(colors_extracted[i])\n",
    "\n",
    "        print(\"New\")\n",
    "        print(new_colors_extracted[i])\n",
    "        \n",
    "        print(\"Desired\")\n",
    "        print(real_colors[i])\n",
    "        \n",
    "        try:\n",
    "            dist = np.array(new_colors_extracted[i]) - np.array(real_colors[i])\n",
    "        except:\n",
    "            dist = \"There is no number\"\n",
    "        print(\"Distance from the desired ones\")\n",
    "        print(dist)\n",
    "\n",
    "        print(\"**********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-system",
   "metadata": {},
   "source": [
    "The results of the color correction aren't very exciting,but we have at least shortened the distance from the desired colors and the extracted ones. I think we need to change approach on the color correction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
