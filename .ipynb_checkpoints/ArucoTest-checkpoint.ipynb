{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corporate-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "ARUCO_DICT = {\n",
    "\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
    "\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
    "\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
    "\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
    "\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "completed-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to incapsulate the imshow, just for prettify the code\n",
    "\"\"\"\n",
    "def imshow(img, name = \"img\"):\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "This method is the preprocessing pipeline. I needed to \n",
    "change it from the classic method because the \n",
    "first implementation wasn't enough efficient on \n",
    "extracting the corners without introducing noise inside\n",
    "its output.\n",
    "\"\"\"\n",
    "def bilateralFilteringPreprocessing(img):\n",
    "    \n",
    "    #Get only one channel\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Blur the image using gaussian blur\n",
    "    imgBlur = cv2.GaussianBlur(gray,(7,7),2)\n",
    "    \n",
    "    # Smoothing without removing edges.\n",
    "    gray_filtered = cv2.bilateralFilter(gray, 9, 60, 120)\n",
    "  \n",
    "    # Applying the canny filter\n",
    "    edges_filtered = cv2.Canny(gray_filtered, 30, 50) \n",
    "\n",
    "    return edges_filtered\n",
    "\n",
    "path = \"C:/Users/User Pc/Desktop/Progetto OpenCV/All notebooks/prototype_aruco_v_0.4_real.jpg\"\n",
    "img = cv2.imread(path)\n",
    "imshow(bilateralFilteringPreprocessing(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mature-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Object that contains the parameters extracted from cv2.aruco.DetectMarkers\n",
    "just for cleaner code\n",
    "\"\"\"\n",
    "class arucoBox():\n",
    "    def __init__(self,topLeft, topRight, bottomRight, bottomLeft, idx):\n",
    "        self.topLeft = topLeft\n",
    "        self.topRight = topRight\n",
    "        self.bottomRight = bottomRight\n",
    "        self.bottomLeft = bottomLeft\n",
    "        self.idx = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "important-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an image in input, returns a list that contains\n",
    "the arucoBox object identified from cv2.aruco.detectMarkers\n",
    "\"\"\"\n",
    "def getArucos(img):\n",
    "    \n",
    "    #Get the arucoDict defined earlier\n",
    "    arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[\"DICT_4X4_50\"])\n",
    "    \n",
    "    #Generate the detector obj\n",
    "    arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "   \n",
    "    #Detect the different arucoBoxes inside the img\n",
    "    (corners, ids, rejected) = cv2.aruco.detectMarkers(img, arucoDict, parameters=arucoParams)\n",
    "    arucos = []\n",
    "    for (i,value) in zip(ids,corners):\n",
    "        \n",
    "        #Unpack the aruco coordinates\n",
    "        (topLeft, topRight, bottomRight, bottomLeft) = value[0] \n",
    "        \n",
    "        #Store them inside an array\n",
    "        arucos.append(arucoBox(topLeft, topRight, bottomRight, bottomLeft,i[0]))\n",
    "        \n",
    "    return arucos\n",
    "\n",
    "arucos = getArucos(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recorded-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of Arucos Markers and the image, gets \n",
    "the references using the markers with idx 1 and 2.\n",
    "Also is useful to return the range of the xAxis so that\n",
    "we can reuse it later to cut the chemical pads from the photo\n",
    "\"\"\"\n",
    "def getReferences(arucos,img):\n",
    "    #For the way the tester its structured, we need just the idx1 and 2\n",
    "    aruco_1 = [aruco for aruco in arucos if aruco.idx == 1][0]\n",
    "    aruco_2 = [aruco for aruco in arucos if aruco.idx == 2][0]\n",
    "    return img[int(aruco_2.bottomRight[1]):int(aruco_1.topLeft[1]),\n",
    "              int( aruco_2.bottomRight[0]):int(aruco_1.topLeft[0])],int( aruco_2.bottomRight[0]),int(aruco_1.topLeft[0])\n",
    "\n",
    "references,x_right,x_left = getReferences(arucos,img)\n",
    "imshow(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "excess-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method that return all the lines in the tester and also the min and max points \n",
    "from them, so that we can crop the image\n",
    "\"\"\"\n",
    "def getContourWithDefinedNumber(img, numberDesired):\n",
    "    \n",
    "  imgContour = img.copy()\n",
    "  imgCanny = bilateralFilteringPreprocessing(img)\n",
    "  #Store couple [[x_Start,y_Start], [X_End,y_End]] for each contour that we found\n",
    "  #with the desired number of boundary points\n",
    "  output = []\n",
    "\n",
    "  #Extract all the contours from the img\n",
    "  contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_LIST,\n",
    "                                        cv2.CHAIN_APPROX_NONE)\n",
    "  #For each contour found\n",
    "  for cnt in contours:\n",
    "        \n",
    "    #Calculate the approximative Polygon to extract only the lines from the photo\n",
    "    peri = cv2.arcLength(cnt,True)\n",
    "     \n",
    "    #Find the approximative Polygon based on the perimeter and the contour\n",
    "    #approx is a list of points that define the polygon\n",
    "    approx = cv2.approxPolyDP(cnt,0.02 * peri,True)\n",
    "    \n",
    "    #Number of corners of the polygon\n",
    "    objCor = len(approx)\n",
    "    \n",
    "    #Return only the contours that have only the desired value\n",
    "    if (objCor == numberDesired):\n",
    "      \n",
    "      #Draw the desired contour\n",
    "      cv2.drawContours(imgContour,cnt,-1,(255,0,0),1)\n",
    "      \n",
    "      #Define the boundingRect so that, in the case of a line o a square, we have\n",
    "      #The left coordinate, the width and the height\n",
    "      x,y,w,h = cv2.boundingRect(approx)\n",
    "      \n",
    "      #Just for us to visualize the output\n",
    "      cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        \n",
    "      output.append(approx)\n",
    "  #Show the output\n",
    "  imshow(imgContour,str(numberDesired))\n",
    "\n",
    "#Extract the lines from the tester using Canny Algorithm and cv2.drawContours\n",
    "getContourWithDefinedNumber(img,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pleasant-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Object that packs different methods useful for the color extraction from \n",
    "each bounding box\n",
    "\"\"\"\n",
    "class boxObject():\n",
    "    \n",
    "    #Init method\n",
    "    def __init__(self,x,y,w,h):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.area = w*h\n",
    "    \n",
    "    #Given an image and a radius(predefine at 0.3), the method return the RGB of the area defined by the radius.\n",
    "    def colorInside(self,img, radius = 0.1):\n",
    "        \n",
    "        #Extract the bounding Rect from the photo\n",
    "        imageInside = img[self.y:self.y+self.h,self.x:self.x+self.w].copy()\n",
    "        \n",
    "        #Define the radius based on the w and h of the box\n",
    "        radiusX = round(radius * self.w) \n",
    "        radiusY = round(radius * self.h)\n",
    "        \n",
    "        #Find the center from radiusX and radiusY\n",
    "        center = imageInside[radiusX : 2*radiusX, radiusY : 2*radiusY]\n",
    "        \n",
    "        #Return the BGR of the area\n",
    "        return [round(np.mean(center[:,:,0])),round(np.mean(center[:,:,1])),round(np.mean(center[:,:,2]))]\n",
    "    \n",
    "    def print(self):\n",
    "        print(self.x,self.y,self.h,self.w)\n",
    "    \n",
    "    #Check if other is a duplicate of self\n",
    "    def is_duplicate_of(self, other):\n",
    "        x_dist = abs(self.x - other.x)\n",
    "        y_dist = abs(self.y - other.y)\n",
    "        area_div = self.area/other.area\n",
    "        return (x_dist < 10 and \n",
    "                y_dist < 10 and \n",
    "                area_div > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prompt-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given an image and the number of vertex desired, returns a list\n",
    "that contains the (x,y,w,h) of each elements that has pol edges\n",
    "Used to extract the coordinates of each square\n",
    "\"\"\"\n",
    "def getPolygonCoords(img,pol = 2):\n",
    "  imgContour = img.copy()\n",
    "  #Preprocessing the image\n",
    "  imgCanny = bilateralFilteringPreprocessing(img)\n",
    "    \n",
    "  #Find the contours so that we can choose the ones desired\n",
    "  contours,hierarchy = cv2.findContours(imgCanny,cv2.RETR_LIST,\n",
    "                                        cv2.CHAIN_APPROX_NONE)\n",
    "  #Output array\n",
    "  boxes = []\n",
    "    \n",
    "  #For each contours\n",
    "  for cnt in contours:\n",
    "    \n",
    "    #Find the perimeter of the contour\n",
    "    peri = cv2.arcLength(cnt,True)\n",
    "    \n",
    "    #Find the approximative Polygon based on the perimeter and the contour\n",
    "    #approx is a list of points that define the polygon\n",
    "    approx = cv2.approxPolyDP(cnt,0.02 * peri,True)\n",
    "    \n",
    "    #If has the desired number of corners\n",
    "    if (len(approx) == pol):\n",
    "      \n",
    "      #Draw for each contour it's shape\n",
    "      cv2.drawContours(imgContour,cnt,-1,(0,255,0),1)\n",
    "    \n",
    "      #Find the bounding rect of the approximative polygon\n",
    "      x,y,w,h = cv2.boundingRect(approx)\n",
    "        \n",
    "      #Append it to the output array\n",
    "      boxes.append(boxObject(x,y,w,h))\n",
    "  \n",
    "  #Just to show the different boxes extracted\n",
    "  imshow(imgContour)\n",
    "  return boxes\n",
    "\n",
    "\"\"\"\n",
    "Given an image in input, returns the (min,max) of the y_coords of the lines inside the photo.\n",
    "Useful to isolate the references\\chemical_pads\n",
    "\"\"\"\n",
    "def getLinesCoords(img):\n",
    "    l = getPolygonCoords(img,2)\n",
    "    #Choose only the horizontal lines inside the img\n",
    "    lines = [value for value in l if(value.h/value.w <0.1)]\n",
    "    #Compact way to iterate,using the generators functions\n",
    "    y_max = max(value.y for value in lines)\n",
    "    y_min = min(value.y for value in lines)\n",
    "    return y_min,y_max\n",
    "\n",
    "#We just need the min or the max because the image contains for now\n",
    "#Just one horizontal line\n",
    "y_chemical_line,_ = getLinesCoords(img)\n",
    "\n",
    "chemical_pads = img[y_chemical_line:,x_right:x_left]\n",
    "\n",
    "#The image of the chemical pads extracted from the tester\n",
    "imshow(chemical_pads)\n",
    "#The contours extracted from the chemical pads image\n",
    "getContourWithDefinedNumber(chemical_pads,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
